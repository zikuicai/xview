# -*- coding: utf-8 -*-
"""kaggle2018dsbowl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fhjOa8NLcFrpqoww28M2-xgDw86aKD0C

## initialization
"""

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

ls -l / | grep drive

cd /

# if you want to mount your drive
!mkdir -p /drive
!google-drive-ocamlfuse drive
!ls | grep drive

"""## get kaggle data"""

# install kaggle
!pip install kaggle
!mkdir /content/.kaggle/
!cp /drive/kaggle/kaggle.json /content/.kaggle/
!chmod 600 /content/.kaggle/kaggle.json

!kaggle competitions download -c data-science-bowl-2018

cd /content/.kaggle/competitions/data-science-bowl-2018/

!mkdir stage1_train/
!unzip stage1_train.zip -d stage1_train/
!mkdir stage1_test/
!unzip stage1_test.zip -d stage1_test/

# find the number of items in the folder
!find stage1_train/ -mindepth 3 -maxdepth 3| wc -l
!find stage1_test/ -mindepth 3 -maxdepth 3| wc -l

!cp /drive/kaggle/model-dsbowl2018-1.h5 /content/.kaggle/competitions/data-science-bowl-2018/model-dsbowl2018-1.h5
!ls /content/.kaggle/competitions/data-science-bowl-2018/

"""## code

### prepare data
"""

# install tqdm
!pip install tqdm

# tabulate for making table
!pip install tabulate

import os
import sys
import random
import warnings

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tqdm import tqdm
from tabulate import tabulate

import cv2

from keras.models import Model, load_model
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K

import tensorflow as tf

# Set some parameters
IMG_WIDTH = 128
IMG_HEIGHT = 128
IMG_CHANNELS = 3
TRAIN_PATH = '/content/.kaggle/competitions/data-science-bowl-2018/stage1_train/'
TEST_PATH = '/content/.kaggle/competitions/data-science-bowl-2018/stage1_test/'

warnings.filterwarnings('ignore', category=UserWarning, module='skimage')
seed = 42
random.seed = seed
np.random.seed = seed

# Get train and test IDs
train_ids = next(os.walk(TRAIN_PATH))[1]
test_ids = next(os.walk(TEST_PATH))[1]

"""#### resize the images"""

# Get train images (convert BGR to RGB), ground truth and masks
X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)
Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
M_train = []
print('Getting and resizing train images and masks ... ')
sys.stdout.flush()
for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):
    path = TRAIN_PATH + id_
    img = cv2.imread(path + '/images/' + id_ + '.png', cv2.IMREAD_COLOR)[:,:,::-1]
    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), cv2.INTER_AREA)
    X_train[n]=img
    
    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
    M = []
    for mask_file in next(os.walk(path + '/masks/'))[2]:
        mask_ = cv2.imread(path + '/masks/' + mask_file, cv2.IMREAD_GRAYSCALE)
        mask_ = cv2.resize(mask_, (IMG_HEIGHT, IMG_WIDTH), cv2.INTER_AREA)
        M.append(mask_)
        mask_ = np.expand_dims(mask_, axis=-1)
        mask = np.maximum(mask, mask_)
    Y_train[n]=mask
    M_train.append(M)
# Get and resize test images
X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)
sizes_test = []
print('Getting and resizing test images ... ')
sys.stdout.flush()
for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):
    path = TEST_PATH + id_
    img = cv2.imread(path + '/images/' + id_ + '.png', cv2.IMREAD_COLOR)[:,:,::-1]
    sizes_test.append([img.shape[0], img.shape[1]])
    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), cv2.INTER_AREA)
    X_test[n]=img

print('Done!')

"""#### check shape"""

# check data shapes
# bach, height, width, channels
print(X_train.shape,X_train.dtype)
print(Y_train.shape,Y_train.dtype)
print(X_test.shape,X_test.dtype)

"""#### without resizing the images"""

# Get train images and masks
X_train = []
Y_train = []
print('Getting and resizing train images and masks ... ')
sys.stdout.flush()
for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):
    path = TRAIN_PATH + id_
    img = cv2.imread(path + '/images/' + id_ + '.png', cv2.IMREAD_COLOR)
    X_train.append(img)
    
    mask = np.zeros_like(img[:,:,:1])
    for mask_file in next(os.walk(path + '/masks/'))[2]:
        mask_ = cv2.imread(path + '/masks/' + mask_file, cv2.IMREAD_GRAYSCALE)
        mask_ = np.expand_dims(mask_, axis=-1)
        mask = np.maximum(mask, mask_).astype(bool)
    Y_train.append(mask)

# Get and resize test images
X_test = []
print('Getting and resizing test images ... ')
sys.stdout.flush()
for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):
    path = TEST_PATH + id_
    img = cv2.imread(path + '/images/' + id_ + '.png', cv2.IMREAD_COLOR)
    X_test.append(img)

print('Done!')

"""#### check shape"""

# check data shapes
# bach
print(len(X_train),type(X_train))
print(len(Y_train),type(Y_train))
print(len(X_test),type(X_test))

# check data shapes
# height, width, channels
ix = 10
print(X_train[ix].shape, X_train[ix].dtype)
print(Y_train[ix].shape, Y_train[ix].dtype)
print(X_test[ix].shape, X_test[ix].dtype)

cp /drive/kaggle/model-dsbowl2018-1.h5 model-dsbowl2018-1.h5

cd /content/.kaggle/competitions/data-science-bowl-2018/

ls

"""### model"""

# Define IoU metric
def mean_iou(y_true, y_pred):
    prec = []
    for t in np.arange(0.5, 1.0, 0.05):
        y_pred_ = tf.to_int32(y_pred)
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2, y_true)
        K.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        prec.append(score)
    return K.mean(K.stack(prec), axis=0)

# Build U-Net model
inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
s = Lambda(lambda x: x / 255) (inputs)

c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)
c1 = Dropout(0.1) (c1)
c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)
p1 = MaxPooling2D((2, 2)) (c1)

c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)
c2 = Dropout(0.1) (c2)
c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)
p2 = MaxPooling2D((2, 2)) (c2)

c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)
c3 = Dropout(0.2) (c3)
c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)
p3 = MaxPooling2D((2, 2)) (c3)

c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)
c4 = Dropout(0.2) (c4)
c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)
p4 = MaxPooling2D(pool_size=(2, 2)) (c4)

c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)
c5 = Dropout(0.3) (c5)
c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)

u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)
u6 = concatenate([u6, c4])
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)
c6 = Dropout(0.2) (c6)
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)

u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)
u7 = concatenate([u7, c3])
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)
c7 = Dropout(0.2) (c7)
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)

u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)
u8 = concatenate([u8, c2])
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)
c8 = Dropout(0.1) (c8)
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)

u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)
u9 = concatenate([u9, c1], axis=3)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)
c9 = Dropout(0.1) (c9)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)

outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

model = Model(inputs=[inputs], outputs=[outputs])
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[mean_iou])
# model.summary()

# Fit model
earlystopper = EarlyStopping(patience=5, verbose=1)
checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)
results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, 
                    callbacks=[earlystopper, checkpointer])

# Predict on train, val and test
model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})
preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)
preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)
preds_test = model.predict(X_test, verbose=1)

# Threshold predictions
# it's a problem to choose the right threshold
thresh = 0.5
preds_train_t = (preds_train > thresh)
preds_val_t = (preds_val > thresh)
preds_test_t = (preds_test > thresh)

# Create list of upsampled test masks
preds_test_upsampled = []
for i in range(len(preds_test)):
    preds_test_upsampled.append(cv2.resize(np.squeeze(preds_test[i]), 
                                           (sizes_test[i][0], sizes_test[i][1]), 
                                           cv2.INTER_AREA)>thresh)

"""### functions"""

# find ix by id
def get_train_ix(str):
  return train_ids.index(str)

def get_test_ix(str):
  return test_ids.index(str)

# show a single image
def show(img):
#   plt.figure(figsize=(12, 12))
  plt.imshow(np.squeeze(img), cmap='gray')
  plt.axis('off')
  plt.title(img.shape)
  plt.show()

# show the original image and its ground truth
def showpair_train_ix(ix):
  plt.figure(figsize=(12, 12))
  images = [X_train[ix],Y_train[ix]]
  titles = ['orimg','g.t.']
  for i in range(len(titles)):
    plt.subplot(1, 2, i+1)
    plt.imshow(np.squeeze(images[i]), cmap='gray')
    plt.axis('off')
    plt.title(titles[i])
  plt.show()

def showpair_test_ix(ix):
  plt.figure(figsize=(12, 12))
  images = [X_test[ix], preds_test_t[ix]]
  titles = ['orimg', 'prediction']
  for i in range(len(titles)):
    plt.subplot(1, 2, i+1)
    plt.imshow(np.squeeze(images[i]), cmap='gray')
    plt.axis('off')
    plt.title(titles[i])
  plt.show()

# show the difference between the g.t. and the prediction
# should be XOR here, instead of substraction

def diff(img1,img2):
  img = img1 ^ img2
  return img 

def diff_train_ix(ix):
  img = Y_train[ix] ^ preds_train_t[ix]
  return img
  
# sanity check on training smaples
def sanity_train_ix(ix):
  plt.figure(figsize=(12,12))
  
  d = diff_train_ix(ix)
  images = [X_train[ix], d, Y_train[ix], preds_train_t[ix]]
  titles = ['orimg', 'diff', 'g.t.', 'prediction']
  
  for i in range(len(titles)):
    plt.subplot(2, 2, i+1)
    plt.imshow(np.squeeze(images[i]), cmap='gray')
    plt.axis('off')
    plt.title(titles[i])
  plt.show()

# sanity check on validation samples
def sanity_val_ix(ix):
  plt.figure(figsize=(12,12))
  
  d = diff(Y_train[int(Y_train.shape[0]*0.9):][ix], preds_val_t[ix])
  images = [X_train[int(X_train.shape[0]*0.9):][ix], d, 
            Y_train[int(Y_train.shape[0]*0.9):][ix], preds_val_t[ix]]
  titles = ['orimg', 'diff', 'g.t.', 'prediction']
  
  for i in range(len(titles)):
    plt.subplot(2, 2, i+1)
    plt.imshow(np.squeeze(images[i]), cmap='gray')
    plt.axis('off')
    plt.title(titles[i])
  plt.show()

# informatioin
def info(img):
  if(type(img)==list): 
    print(tabulate([
                  ['length', len(img)], 
                  ], headers=['list', ''], tablefmt="fancy_grid"),'\n')
  elif(type(img)==np.ndarray):
    print(tabulate([
                  ['shape', img.shape], 
                  ['dtype', img.dtype], 
                  ['maxValue', np.amax(img)], 
                  ['minValue', np.amin(img)],
                  ['#unique',len(np.unique(img))]
                  ], headers=['np.ndarray', ''], tablefmt="fancy_grid"),'\n')
  else: print('This is a ', type(img))

def iou_metric(y_gt, y_pred, print_table=False):
    gtNum, gtLabel = cv2.connectedComponents(y_gt.astype(np.uint8))
    predNum, predLabel = cv2.connectedComponents(y_pred.astype(np.uint8))

    intersection = np.histogram2d(gtLabel.flatten(), predLabel.flatten(), bins=(gtNum, predNum))[0]

    # Compute areas (needed for finding the union between all objects)
    area_true = np.histogram(gtLabel, bins = gtNum)[0]
    area_pred = np.histogram(predLabel, bins = predNum)[0]
    area_true = np.expand_dims(area_true, -1)
    area_pred = np.expand_dims(area_pred, 0)

    # Compute union
    union = area_true + area_pred - intersection

    # Exclude background from the analysis
    intersection = intersection[1:,1:]
    union = union[1:,1:]
    union[union == 0] = 1e-9

    # Compute the intersection over union
    iou = intersection / union

    # Precision helper function
    def precision_at(threshold, iou):
        matches = iou > threshold
        true_positives = np.sum(matches, axis=1) == 1   # Correct objects
        false_positives = np.sum(matches, axis=0) == 0  # Missed objects
        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects
        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)
        return tp, fp, fn

    # Loop over IoU thresholds
    prec = []
    if print_table:
        print("Thresh\tTP\tFP\tFN\tPrec.")
    for t in np.arange(0.5, 1.0, 0.05):
        tp, fp, fn = precision_at(t, iou)
        if (tp + fp + fn) > 0:
            p = tp / (tp + fp + fn)
        else:
            p = 0
        if print_table:
            print("{:1.3f}\t{}\t{}\t{}\t{:1.3f}".format(t, tp, fp, fn, p))
        prec.append(p)

    if print_table:
        print("AP\t-\t-\t-\t{:1.3f}".format(np.mean(prec)))
    return np.mean(prec)

def iou_metric_batch(y_true_in, y_pred_in):
    batch_size = y_true_in.shape[0]
    metric = []
    for batch in range(batch_size):
        value = iou_metric(y_true_in[batch], y_pred_in[batch])
        metric.append(value)
    return np.array(np.mean(metric), dtype=np.float32)

def my_iou_metric(label, pred):
    metric_value = tf.py_func(iou_metric_batch, [label, pred], tf.float32)
    return metric_value

# split img to masks
def img2masks(img):
  if(img.dtype != np.uint8):
    img = img.astype(np.uint8)
  masks = []
  num, label = cv2.connectedComponents(img)
  for i in range(1,num):
    masks.append(label == i)
  return masks

# get the single masks
M_gt = []
for img in Y_train:
  masks = img2masks(img)
  M_gt.append(masks)

# get the single masks
M_pred = []
for img in preds_train_t:
  masks = img2masks(img)
  M_pred.append(masks)

def iou(A, B, name = 'IOU'):
  # Function:
  # compute the IOU levels of 2 single masks
    intersection = np.logical_and(A, B)
    union = np.logical_or(A, B)
    iou = np.sum(intersection > 0) / np.sum(union > 0)
    s = pd.Series(name = name)
    for thresh in np.arange(0.5,1,0.05):
        s[thresh] = iou > thresh
    return s


def hit_matrix(P,G,thresh=0.5,show=False):
  # Function: 
  # compute the hit matrix of 2 decks of masks
  # Input:
  # prediction, ground truth and IOU threshold
  lp = len(P)
  lg = len(G)
  print('P =',lp,', G =',lg)
  th = round((thresh - 0.5)/0.05)
  # th should be in range(0,9,1)
  if(th > 9): th = 9
  if(th < 0): th = 0
  # 10 threshols in np.arange(0.5,1,0.05))
  iouMat = np.zeros([10, lp, lg])
  for i, p in enumerate(P):
    for j, gt in enumerate(G):
        s = iou(p, gt, 'P{}-GT{}'.format(i,j))
        iouMat[:,i,j] = s.values
        
  if show:  
    fig, axs = plt.subplots()
#   fig, axs = plt.subplots(figsize=(12, 12))
    axs.imshow(iouMat[th], cmap='gray')
    
    p_labels = ['P{}'.format(x) for x in range(lp)]
    gt_labels = ['GT{}'.format(x) for x in range(lg)]
    axs.set_xticks(range(lg))
    axs.set_xticklabels(gt_labels, rotation=45, fontsize=16)
    axs.set_yticks(range(lp))
    axs.set_yticklabels(p_labels, fontsize=16)
    axs.set_title('Hit Matrix at thresh = {}'.format(th*0.05+0.5), fontsize=18)
    plt.tight_layout()
    plt.show()
    
  return iouMat

sanity_train_ix(3)

ix = 3
mat = hit_matrix(M_pred[ix],M_gt[ix],thresh = 0.5, show = True)

def single_iou_score(mat, thresh = 0.5):
  # Input:
  # hit_matrix at a certain IOU threshold
  
  th = round((thresh - 0.5)/0.05)
  if(th > 9): th = 9
  if(th < 0): th = 0
  th = int(th)
  # 10 threshols in np.arange(0.5,1,0.05))
  # if P can find a G
  tp = np.sum(mat[th].sum(axis=1) > 0)
  # if P has no corresponding G
  fp = np.sum(mat[th].sum(axis=1) == 0 )
  # if G has no P associated with
  fn = np.sum(mat[th].sum(axis=0) == 0 )
  p = tp / (tp + fp + fn)
  
#   print('At threshold {}:\n\tTP = {}\n\tFP = {}\n\tFN = {}\n\tp = {:0.3f}'
# .format((th*0.05+0.5), tp, fp, fn, p))
  return tp, fp, fn, p


def mean_iou_score(mat):
  # Input:
  # hit_matrix of an image over 10 IOUs
  
  ps = []
  for thresh in np.arange(0.5, 1, 0.05):
    _,_,_,p = single_iou_score(mat, thresh)
#     print('\tt({:0.2f}) = {:0.3f}'.format(round(thresh,2), p))
    ps.append(p)
    score = np.mean(ps)
  return score

def score(pic1,pic2):
  # Function:
  # input 2 mask images, output the score
  m1 = img2masks(pic1)
  m2 = img2masks(pic2)
  mat = hit_matrix(m1,m2)
  return mean_iou_score(mat)

print(score(preds_train_t[3],Y_train[3]))
print(score(Y_train[3],preds_train_t[3]))

print('Mean precision for this image is: {:0.3f}'.format(mean_iou_score(mat)))

info(M_train[0][0])
fig, axes = plt.subplots(1,2,figsize=(12,9))
axes[0].imshow(M_train[0][0], cmap='gray')
axes[1].imshow(M_train[0][1], cmap='gray')
for i, ax in enumerate(axes):
  ax.axis('off')

"""#### doubt on the iou matric

---

| # g.t. | # pred | train_id |
|--- | --- | ---|
|7  |7  |1e61ecf354cb93a62a9561db87a53985fb54e001444f98112ed0fc623fad793e|
|11 |10 |3874755f6222e83006fdad4d664ec0d9697c13af4fbe24b2f9a059bb13075186|
|2  |3  |e5aeb5b3577abbebe8982b5dd7d22c4257250ad3000661a42f38bf9248d291fd|

---

when the number of g.t. is the same as prediction, this code should work fine. \
but when the number predicted labels is different from g.t., the problem is how the number of labels will match each other
"""

ix = get_train_ix('e5aeb5b3577abbebe8982b5dd7d22c4257250ad3000661a42f38bf9248d291fd')
sanity_train_ix(ix)

# 38: both 7  1e61ecf354cb93a62a9561db87a53985fb54e001444f98112ed0fc623fad793e

# 19: 11 10  3874755f6222e83006fdad4d664ec0d9697c13af4fbe24b2f9a059bb13075186

# 240: 2 3  e5aeb5b3577abbebe8982b5dd7d22c4257250ad3000661a42f38bf9248d291fd

mix = 240
minx = 3
for i in range(100):
  y_gt = Y_train[ix]
  y_pred = preds_train_t[ix]

  labelsNum, labels = cv2.connectedComponents(y_gt.astype(np.uint8))
  predNum, y_pred = cv2.connectedComponents(y_pred.astype(np.uint8))
  
  if(labelsNum<10 and predNum != labelsNum):
    if(labelsNum<minx): 
      minx = labelsNum
      mix = ix
  ix = ix + 1
print('#', mix, '\n')

ix = 240
y_gt = Y_train[ix]
y_pred = preds_train_t[ix]

labelsNum, labels = cv2.connectedComponents(y_gt.astype(np.uint8))
predNum, y_pred = cv2.connectedComponents(y_pred.astype(np.uint8))

print(labelsNum)
print(predNum)

# info(labels)
# info(y_pred)
intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]
info(intersection)

area_true = np.histogram(labels, bins = true_objects)[0]
area_pred = np.histogram(y_pred, bins = pred_objects)[0]
# info(area_true)
# info(area_pred)

area_true = np.expand_dims(area_true, -1)
area_pred = np.expand_dims(area_pred, 0)
# info(area_true)
# info(area_pred)

union = area_true + area_pred - intersection
info(union)

sanity_train_ix(ix)

o = [0,1,1,2,2,2]
o1 = [0,0,1,2,2,2]
h = np.histogram(o,bins=3)[0]
h1 = np.histogram(o1,bins=3)[0]
h = np.expand_dims(h, -1)
h1 = np.expand_dims(h1, 0)
print(h,h1)

u = h + h1
print(u)

i = np.histogram2d(o, o1, bins=(3, 3))[0]
print(i)

# plt.hist(labels.flatten(), bins= true_objects)
# plt.show()

# hi = np.histogram(labels.flatten(), bins=true_objects)[0]
# info
aa = [0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3]
# print(len(aa))
his = np.histogram(aa, bins=4)[0]
# plt.imshow(his)

plt.hist(aa, bins = 4)
plt.show()

# Compute areas (needed for finding the union between all objects)
    area_true = np.histogram(labels, bins = true_objects)[0]
    area_pred = np.histogram(y_pred, bins = pred_objects)[0]
    area_true = np.expand_dims(area_true, -1)
    area_pred = np.expand_dims(area_pred, 0)

show(labels>0)
show(y_pred>0)

ix = 0
iou_metric(np.squeeze(Y_train[ix]), np.squeeze(preds_train_t[ix]), print_table=True)

"""### note
```

incorrect g.t. of train smaples
# 634, 422, 536, 513, 130

```
"""

# Check if training data looks all right
# special numbers: 55, 111
ix = random.randint(0, len(train_ids))
# ix = 524
print('id = {}'.format(ix))
showpair_train_ix(ix)









"""### results

#### shapes and types
"""

ix = 0
print(preds_train[ix].dtype)
show(preds_train[ix])
print(preds_train_t[ix].dtype)
show(preds_train_t[ix])

print(preds_train[ix].dtype)
print(len(np.unique(preds_train[ix])))
print(np.amax(preds_train[ix]))
print(np.amin(preds_train[ix]))

print('\n')

img1 = preds_train[ix]*255
img11  = img1.astype(np.uint8)
info(img1)
info(img11)

ret3,th3 = cv2.threshold(img11,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
info(th3)
# show(th3)
show(diff(th3,np.squeeze(preds_train_t[ix])))

# train data
print('train:')
print(X_train.shape, X_train.dtype)
print(Y_train.shape, Y_train.dtype)
print(preds_train.shape, preds_train.dtype)
print(preds_train_t.shape, preds_train_t.dtype)
print(preds_val.shape, preds_val.dtype)
print(preds_val_t.shape, preds_val_t.dtype)
print('\n')

# test data
print('test:')
print(X_test.shape, X_test.dtype)
print(preds_test.shape, preds_test.dtype)
print(preds_test_t.shape, preds_test_t.dtype)
print('\n')
# 0 or 1

print(preds_train.dtype)
plt.imshow(np.squeeze(preds_train[0]), cmap='gray')
plt.colorbar()
plt.axis('off')
plt.title('before threshold')
plt.show()

print(preds_train_t.dtype)
plt.imshow(np.squeeze(preds_train_t[0]), cmap='gray')
plt.axis('off')
plt.title('after threshold')
plt.show()

print(Y_train.dtype)
plt.imshow(np.squeeze(Y_train[0]), cmap='gray')
plt.axis('off')
plt.title('g.t.')
plt.show()

# sanity train
ix = 524
# ix = random.randint(0, len(preds_train_t)-1)
print('ix =',ix)
sanity_train_ix(ix)

# sanity validation
ix = 2
# ix = random.randint(0, len(preds_val_t)-1)
print('ix =', ix)
sanity_val_ix(ix)

# show the prediction
# ix = 2
ix = random.randint(0, len(preds_val_t)-1)
print('ix =', ix)
showpair_test_ix(ix)

"""Note: there are some different kinds of images such as 

```
train[222] : single cell or a ring

val[0] : 
val[1] : purple
val[2] : normal

```

the g.t. of 
```
train[275]

val[47] 
```
doesn't look right

hard cases
```

train[200]
```

### encode and export csv
"""

# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python
def rle_encoding(x):
    dots = np.where(x.T.flatten() == 1)[0]
    run_lengths = [] 
    prev = -2
    for b in dots:
        if (b>prev+1): run_lengths.extend((b + 1, 0))
        run_lengths[-1] += 1
        prev = b
    return run_lengths

# Encode regions one by one
def prob_to_rles(x, cutoff=0.5):
    lab_num, lab_img = cv2.connectedComponents(x > cutoff)
    for i in range(1, lab_num):
        yield rle_encoding(lab_img == i)

# preds_train_t[0].shape
# len(preds_test_upsampled)
ix = 0
img = preds_test_upsampled[ix]
print(img.shape, img.dtype)
print(test_ids[ix])



run_lengths.extend((2999+1, 0))
run_lengths

print(img.shape,'=',img.shape[0]*img.shape[1])
rle_encoding(img)

new_test_ids = []
rles = []
for n, id_ in enumerate(test_ids):
    rle = list(prob_to_rles(preds_test_upsampled[n]))
    rles.extend(rle)
    new_test_ids.extend([id_] * len(rle))

# Create submission DataFrame
sub = pd.DataFrame()
sub['ImageId'] = new_test_ids
sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))
sub.to_csv('sub-dsbowl2018-1.csv', index=False)

ls /drive/

